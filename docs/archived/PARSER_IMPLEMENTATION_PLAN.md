# Parser Implementation Plan: Achieving Full Feature Parity with ScanCode Toolkit

> **‚ö†Ô∏è ARCHIVED DOCUMENT** - February 9, 2026
>
> This document served as a development roadmap and is now archived for historical reference.
>
> **For current information, see:**
>
> - **[HOW_TO_ADD_A_PARSER.md](../HOW_TO_ADD_A_PARSER.md)** - Guide for adding new parsers
> - **[ARCHITECTURE.md](../ARCHITECTURE.md)** - System design and components
> - **[SUPPORTED_FORMATS.md](../SUPPORTED_FORMATS.md)** - List of supported formats
> - **[ADRs](../adr/)** - Architectural decision records
> - **[Improvements](../improvements/)** - Beyond-parity feature documentation
>
> ---
>
> **Final Status** (at time of archival): üü¢ **Phase 1 Complete - 70+ Parsers Implemented**  
> **Original Goal**: Implement all ScanCode Toolkit parsers (40+ ecosystems, 136+ formats) with Rust's safety and performance advantages  
> **Achievement**: 70+ parsers across 24 ecosystems with multiple beyond-parity improvements

## Executive Summary

This document outlines the comprehensive plan to achieve 100% parser feature parity between scancode-rust and ScanCode Toolkit.

**Final Coverage** (Feb 9, 2026): npm, Python, Rust, Maven, Go, Dart, Composer, Ruby, NuGet, Gradle, Swift, CocoaPods, Debian, RPM, Alpine, Conda, CRAN, Conan, Haxe, OPAM, Bower, AboutCode, Chef, CPAN, FreeBSD, Autotools (70+ parsers across 24 ecosystems)  
**Original Target**: ScanCode Toolkit's full coverage (136+ formats across 40+ ecosystems)  
**Status**: Core ecosystems complete with production-ready quality

---

## Latest Progress (February 9, 2026)

### Phase 0.9: Missing Parsers Implementation (‚úÖ Complete - Feb 9, 2026)

**Status**: Wave 0-2 complete, 11 parsers added in single feature branch (`feat/missing-parsers`)

#### Implemented Parsers (11 total, 17 new parser structs)

**Wave 0 - Quick Fix (1 commit)**
- ‚úÖ Conan parsers registered (3 parsers: ConanFilePyParser, ConanfileTxtParser, ConanLockParser)

**Wave 1 - Simple JSON/YAML (2 commits)**
- ‚úÖ BowerJsonParser (`bower.json`) - Legacy JavaScript package manager
- ‚úÖ AboutFileParser (`.ABOUT` files) - AboutCode metadata with purl parsing

**Wave 2 - Medium Complexity (3 commits)**
- ‚úÖ ChefMetadataJsonParser (`metadata.json`) - Chef cookbook JSON manifest
- ‚úÖ FreebsdCompactManifestParser (`+COMPACT_MANIFEST`) - FreeBSD packages with complex license logic
- ‚úÖ AutotoolsConfigureParser (`configure`, `configure.ac`) - Unix build system (parent dir name extraction)

**Wave 3 - Complex Parsers (3 commits)**
- ‚úÖ ChefMetadataRbParser (`metadata.rb`) - Chef Ruby DSL with line-based parsing
- ‚úÖ CPAN parsers (3 parsers: CpanMetaJsonParser, CpanMetaYmlParser, CpanManifestParser) - **BEYOND PARITY**
- ‚è≥ JAR/WAR/EAR parser (deferred - high complexity, 8-12 hours)

**Wave 4 - Build Systems (deferred)**
- ‚è≥ Bazel BUILD parser (deferred - 5-7 hours)
- ‚è≥ Buck parsers (deferred - 5-7 hours)

#### Key Achievements

**1. CPAN Beyond-Parity Implementation**

Python ScanCode has stub-only handlers with no parse() method. Our implementation:
- ‚úÖ Full META.json parsing (CPAN::Meta::Spec v2.0+)
- ‚úÖ Full META.yml parsing (CPAN::Meta::Spec v1.4)
- ‚úÖ MANIFEST file list extraction
- ‚úÖ All 4 dependency scopes (runtime, build, test, configure)
- ‚úÖ Author party extraction with name/email parsing
- ‚úÖ Resource URL extraction (homepage, VCS, bug tracking)
- ‚úÖ Documented in `docs/improvements/cpan-parser.md`

**2. Chef Ruby DSL Parser**

Line-based token extraction without full Ruby parser:
- ‚úÖ Regex-based field extraction
- ‚úÖ Dependency parsing with version constraints
- ‚úÖ IO.read(...) expression skipping (can't evaluate Ruby)
- ‚úÖ Shared build_package() logic with JSON parser

**3. FreeBSD License Logic**

Complex license combination handling:
- ‚úÖ Single license mode
- ‚úÖ AND logic (multiple licenses required)
- ‚úÖ OR/dual logic (alternative licensing)
- ‚úÖ URL construction (code_view_url, download_url)
- ‚úÖ Qualifiers (arch, origin)

#### Test Coverage

- **1011 tests passing** ‚úÖ (up from 907, +104 tests)
- **17 new parsers** registered and working
- **0 clippy warnings** ‚úÖ
- **Atomic commits** with descriptive messages

#### Files Added/Modified

**New Parsers**:
- `src/parsers/bower.rs` (406 lines) + tests
- `src/parsers/about.rs` (279 lines) + tests
- `src/parsers/chef.rs` (enhanced, 2 parsers) + tests
- `src/parsers/freebsd.rs` (303 lines) + tests
- `src/parsers/autotools.rs` (56 lines) + tests
- `src/parsers/cpan.rs` (628 lines, 3 parsers) + tests

**Documentation**:
- `docs/improvements/cpan-parser.md` (255 lines) - Beyond-parity documentation

**Test Data**:
- `testdata/bower/` (5 test files)
- `testdata/about/` (2 test files)
- `testdata/chef/` (enhanced with metadata.rb)
- `testdata/freebsd/` (8 test cases)
- `testdata/autotools/` (2 minimal test files)
- `testdata/cpan/` (3 formats)

#### Implementation Philosophy

**"At least parity, but pick up improvements along the way"**

Applied consistently across all parsers:
- Fixed Python bugs (Alpine SHA1 decoding)
- Implemented Python TODOs (RPM dependencies, Debian .deb introspection)
- Enhanced beyond Python (CPAN real parsing vs stubs, Composer provenance fields)
- Documented all improvements in `docs/improvements/`

---

## Previous Improvements (February 2026)

### Phase 0.8: Linux Distribution Parsers (‚úÖ Complete - Feb 8, 2026)

**Status**: All Phase 4 Linux distribution parsers complete and production-ready

#### Implemented Parsers (3 ecosystems, 8 formats)

**Debian/Ubuntu (5 parsers)**

- ‚úÖ DebianControlParser (`control` files) - RFC822 format parsing
- ‚úÖ DebianDebParser (`.deb` archives) - **BEYOND PARITY**: Full archive introspection (Python has TODO)
- ‚úÖ DebianCopyrightParser (`copyright` files) - DEP-5 machine-readable format
- ‚úÖ DebianDscParser (`.dsc` files) - Source package metadata
- ‚úÖ DebianInstalledParser (dpkg status database) - Installed package tracking

**RPM/RedHat/Fedora (1 parser)**

- ‚úÖ RpmParser (`.rpm` archives) - **BEYOND PARITY**: Dependency extraction with version constraints (Python has TODO)

**Alpine Linux (2 parsers)**

- ‚úÖ AlpineInstalledParser (installed database) - **BEYOND PARITY**: Correct SHA1 decoding + provider field extraction
- ‚úÖ AlpineApkParser (`.apk` archives) - Full PKGINFO extraction

#### Key Achievements

**1. Alpine Parser Enhancements** - Going Beyond Python

**File References with SHA1 Decoding**:

- Python extracts file references but SHA1 is always `null` (bug)
- Our implementation: Correctly decodes Q1-prefixed base64 to hex SHA1
- Extracts F/R/Z/a fields (directory, filename, checksum, attributes)
- Test: Verified 14/14 file references with correct checksums

**Provider Field Extraction** (NEW - Python doesn't implement):

- Extracts `p:` field (commands, shared libraries provided)
- Python explicitly marks as "ignored per-package fields...not used yet"
- Example: `p:/bin/sh cmd:busybox cmd:sh` ‚Üí `["/ /sh", "cmd:busybox", "cmd:sh"]`
- Stores in `extra_data.providers` array

**2. RPM Dependency Extraction** (NEW - Python has TODO)

- Python has multiple TODOs: "add dependencies!!!"
- Our implementation uses `rpm` crate's `get_requires()` API
- Extracts dependency name, version constraints, flags
- Formats requirements: `"libc.so.6 >= 2.2.5"`, `"bash"` (no version)
- Generates proper PURLs for each dependency
- Added `bzip2-compression` feature for better format support

**3. Debian Archive Introspection** (Already implemented - Phase 0.5)

- Python has TODO: "introspect archive"
- Our implementation: Full control.tar.gz extraction from .deb files
- Parses control file and extracts complete metadata
- Test: Verified dependency extraction from real .deb files

#### Beyond Feature Parity Summary

| Parser | Python Status | Our Status | Improvement |
|--------|--------------|------------|-------------|
| Alpine SHA1 | Always `null` (bug) | Correctly decoded | ‚úÖ Bug fix |
| Alpine providers | "not used yet" (TODO) | Full extraction | ‚úÖ New feature |
| RPM dependencies | Multiple TODOs | Full extraction | ‚úÖ New feature |
| Debian .deb | TODO "introspect" | Full introspection | ‚úÖ Implemented |

#### Test Coverage

- **894 tests passing** ‚úÖ (up from 684)
- **13 Alpine tests** (12 passing, 1 intentionally ignored as beyond parity)
- **11 RPM tests** (all passing)
- **Multiple Debian tests** (existing golden tests)
- **0 clippy warnings** ‚úÖ

#### Files Added/Modified

**New Parsers**:

- `src/parsers/debian.rs` - Enhanced with .deb archive extraction (already existed)
- `src/parsers/alpine.rs` - Enhanced with provider field extraction (already existed)
- `src/parsers/rpm_parser.rs` - Enhanced with dependency extraction (already existed)

**Test Files**:

- `src/parsers/alpine.rs` - Added provider field test
- `src/parsers/rpm_parser.rs` - Added dependency extraction test

**Dependencies**:

- `Cargo.toml` - Added `bzip2-compression` feature to rpm crate

#### Implementation Approach

**Alpine Providers**: Case-sensitive field extraction from raw text (Python's RFC822 parser is case-insensitive, loses distinction between `P:` package name and `p:` providers)

**RPM Dependencies**: Leverages rust `rpm` crate's native API for binary format parsing, formats version constraints according to RPM spec (>=, <=, =, <, >)

**Philosophy Applied**: "At least parity, but pick up improvements along the way" - implemented features that Python has as TODOs or bugs.

---

### Phase 0.7: Gradle, Swift, CocoaPods Implementation (‚úÖ Complete - Feb 7, 2026)

**Status**: All Wave 1-2-3 parsers complete and production-ready

#### Implemented Parsers (8 total)

**Wave 1 - Lockfile & JSON Formats (5 parsers)**

- ‚úÖ GradleLockfileParser (`gradle.lockfile`) - Simple text format
- ‚úÖ SwiftPackageResolvedParser (`Package.resolved`) - JSON lockfile, v1/v2/v3 support
- ‚úÖ SwiftManifestJsonParser (`Package.swift.json`) - With BLAKE3 caching
- ‚úÖ PodspecJsonParser (`.podspec.json`) - JSON CocoaPods manifest
- ‚úÖ PodfileLockParser (`Podfile.lock`) - YAML with data aggregation

**Wave 2 - Complex DSL Parsers (3 parsers)**

- ‚úÖ GradleParser (`build.gradle`, `build.gradle.kts`) - Token-based lexer with 5/5 patterns
- ‚úÖ PodspecParser (`.podspec`) - Regex-based Ruby DSL parser
- ‚úÖ PodfileParser (`Podfile`) - Regex-based Ruby DSL parser

**Wave 3 - Golden Tests & Validation**

- ‚úÖ Gradle: 19 golden tests (15 passing, 4 documented as ignored)
- ‚úÖ CocoaPods: 10 golden tests (all ignored - architectural difference documented)
- ‚úÖ Swift: 7 golden tests (all ignored - architectural difference documented)

#### Key Achievement: GradleParser

**Implementation Approach**: Custom token-based lexer + recursive descent parser (exceeded original tree-sitter plan)

**Features Implemented**:

- ‚úÖ All 5 dependency patterns supported
- ‚úÖ Both Groovy and Kotlin DSL
- ‚úÖ String interpolation preservation
- ‚úÖ Nested function calls
- ‚úÖ Project references
- ‚úÖ Map format dependencies
- ‚úÖ Named parameters (with/without parentheses)
- ‚úÖ PURL generation with dollar sign encoding

**Test Coverage**: 14 unit tests + 19 golden tests = 684 total tests passing

**Quality**: Zero clippy warnings, production-ready

#### Architectural Notes

**CocoaPods & Swift Golden Tests**: Intentionally ignored due to architectural difference (not a bug):

- Python: Extracts each dependency as separate package in `{packages: []}`
- Rust: Extracts single PackageData with `dependencies: []` array
- Both approaches valid; comprehensive unit tests (41 tests) verify correctness

**Files Added**:

- `src/parsers/gradle.rs` (870 lines)
- `src/parsers/gradle_golden_test.rs`
- `src/parsers/podspec.rs`
- `src/parsers/podfile.rs`
- `src/parsers/swift_manifest_json.rs`
- `src/parsers/swift_resolved.rs`
- `src/parsers/podspec_json.rs`
- `src/parsers/podfile_lock.rs`
- `src/parsers/cocoapods_golden_test.rs`
- `src/parsers/swift_golden_test.rs`

**Metrics**: +129 tests (555 ‚Üí 684), +3,000+ lines of implementation and tests

---

### Phase 0.6: Golden Test Validation & Parser Fixes (‚úÖ Complete - Feb 7, 2026)

#### Ecosystems Fully Validated

| Ecosystem    | Status      | Golden Tests | Notes                                                      |
| ------------ | ----------- | ------------ | ---------------------------------------------------------- |
| **Go**       | ‚úÖ 100%     | 4/4 passing  | Extracts go_version, detects // indirect correctly         |
| **Dart**     | ‚úÖ 100%     | 4/4 passing  | Improved scope handling, description preservation          |
| **Composer** | ‚úÖ 100%     | 1/1 passing  | Enhanced with richer metadata                              |
| **npm**      | ‚úÖ Enhanced | 4/12 passing | Version pinning detection, PURL generation for pinned deps |
| **NuGet**    | ‚úÖ Enhanced | 0/6 passing  | License normalization, PURL generation, holder field       |
| **Cargo**    | ‚úÖ 100%     | 1/1 passing  | Complete implementation                                    |
| **Python**   | ‚úÖ 100%     | 6/6 passing  | All formats validated                                      |
| **npm**      | üü° 33%      | 4/12 passing | 8 blocked on license engine                                |
| **NuGet**    | üü° 0%       | 0/6 passing  | 6 blocked on URL-to-SPDX mapping                           |
| **Ruby**     | üü° 25%      | 1/4 passing  | 3 blocked (2 license, 1 complex)                           |

#### Key Accomplishments

**1. Dart Parser Improvements**

- Fixed dependency scope extraction (`None` ‚Üí `"dependencies"`)
- Preserved YAML trailing newlines in descriptions (semantic correctness)
- Fixed lockfile `is_direct` field (all entries now `true` - manifest view)
- **Impact**: 4/4 golden tests passing

**2. Ruby Parser Improvements**

- Fixed runtime dependency scope (`None` ‚Üí `"runtime"`)
- Fixed empty version constraints (`None` ‚Üí `""` for Python compatibility)
- Reordered dependency extraction (development first, matching Python output)
- **Intentional Divergence**: Combined party model (name + email together) instead of Python's fragmented approach
- **Rationale**: Semantic correctness - one person = one party, maintains data integrity
- **Impact**: 1/4 golden tests passing, documented improvements

**3. Composer Parser Enhancement**

- Added richer dependency metadata (7 fields in `extra_data`)
- Fields: `source_type`, `source_url`, `source_reference`, `dist_type`, `dist_url`, `dist_reference`, `type`
- **Intentional Improvement**: More complete package provenance tracking
- **Impact**: Better than Python implementation, documented

**4. Golden Test Documentation**

- All 16 failing tests now ignored with `#[ignore]` attribute
- Each includes specific unblock requirements in ignore message
- Comprehensive README files for each ecosystem documenting improvements and blockers

#### Documented Blockers (16 Tests)

**npm Tests (8 ignored) - License Detection Engine Required**

- `test_golden_authors_list_dicts` - license_detections array mismatch
- `test_golden_double_license` - SPDX normalization needed (`"Apache 2.0"` ‚Üí `"Apache-2.0"`)
- `test_golden_express_jwt` - license_detections array length mismatch
- `test_golden_from_npmjs` - License detections and SPDX normalization
- `test_golden_chartist` - License normalization and detection
- `test_golden_dist` - License detections and normalization
- `test_golden_electron` - License normalization

**To Unblock**: Integrate full license detection engine with SPDX normalization

---

**NuGet Tests (6 ignored) - License URL-to-SPDX Mapping Required**

- `test_golden_bootstrap` - `https://github.com/.../license` ‚Üí `"mit"`
- `test_golden_castle_core` - License URL mapping
- `test_golden_entity_framework` - License URL mapping
- `test_golden_jquery_ui` - License URL mapping
- `test_golden_aspnet_mvc` - License URL mapping
- `test_golden_net_http` - License URL mapping

**To Unblock**:

- Create URL-to-SPDX lookup table (e.g., `github.com/.*/license` patterns)
- Implement license file fetching and detection
- OR maintain manual mapping of common license URLs

---

**Ruby Tests (3 ignored) - Mixed Complexity**

1. `test_golden_arel_gemspec` - **High Complexity**
   - Multi-line `%q{...}` string literal evaluation needed
   - Conditional dependencies inside `if/else` blocks
   - **To Unblock**: Ruby AST parser or heuristic extraction (4-8 hours effort)

2. `test_golden_oj_gemspec` - **License Engine**
   - Python expects `null` but we extract `"mit"` from `s.licenses = ['MIT']`
   - **To Unblock**: Investigate Python behavior or integrate license engine

3. `test_golden_rubocop_gemspec` - **License Engine**
   - Same issue as oj - license extraction discrepancy
   - **To Unblock**: Same as oj

#### Philosophy Applied

**"Improve Over Python When It Makes Sense"**

We chose semantic correctness over blind compatibility in Ruby party extraction:

**Python Behavior (Fragmented)**:

```json
[
  { "name": "Alice", "email": null },
  { "name": null, "email": "alice@example.com" }
]
```

**Our Behavior (Semantic)**:

```json
[{ "name": "Alice", "email": "alice@example.com" }]
```

**Rationale**: One person = one party. Preserves data relationships and provides better UX for downstream tools. Documented in `testdata/ruby-golden/README.md`.

---

### Phase 0.5: Parser Quality & Feature Enhancement (‚úÖ Complete - Feb 2025)

#### Wave 1: Safety & Robustness (3 commits)

- **Eliminated panic-prone code**: Replaced all `.unwrap()` and `.expect()` calls with graceful error handling
- **Impact**: 11 potential panic points ‚Üí graceful fallback with warning logs
- **Philosophy**: Match ScanCode Toolkit behavior ("extract what you can, log what you can't, continue scanning")

**Files Modified**:

- `src/parsers/pnpm_lock.rs` - 3 unwrap() calls removed
- `src/parsers/npm.rs` - 2 expect() calls removed
- `src/parsers/cargo.rs` - 4 expect() calls removed
- `src/parsers/python.rs` - 2 expect() calls removed (bundled with cargo.rs commit)

#### Wave 2: Data Consistency & Accuracy (9 commits)

**1. Namespace Standardization** (1 commit)

- **Problem**: Inconsistent handling of scoped package namespaces (@org vs org)
- **Solution**: Standardized all parsers to use `@org` format
- **Impact**: npm and pnpm parsers now consistently return `@babel` instead of `babel`

**2. Direct Dependency Detection** (3 commits)

- **Problem**: `is_direct` field hardcoded to `true` instead of analyzing dependency graph
- **Solution**: Implemented proper detection for 7 parsers
  - npm_lock: Track nesting depth (root level = direct)
  - pnpm_lock: Extract from `importers` section
  - yarn_lock: v1 limitation documented, v2+ workspace detection
  - poetry_lock: Match against pyproject.toml dependencies
  - pipfile_lock: All are direct (by design)
  - maven: All pom.xml dependencies are direct
  - python: All manifest dependencies are direct
- **Impact**: Accurate direct vs transitive dependency tracking

**3. Version Pinning Analysis** (2 commits)

- **Problem**: `is_pinned` field hardcoded instead of analyzing version specifiers
- **Solution**: Implemented version string analysis for 2 parsers
  - cargo: `"1.0.0"` = pinned, `"^1.0.0"` = not pinned (semver analysis)
  - maven: `"1.0.0"` = pinned, `"[1.0,2.0)"` = not pinned (range detection)
- **Impact**: Accurate pinning status for dependency resolution

**4. Hash Extraction Enhancement** (3 commits)

- **Problem**: Parsers only extracted 1-2 hash types instead of all available
- **Solution**: Enhanced 5 parsers to extract all 4 hash types (sha1, sha256, sha512, md5)
  - npm_lock: Added sha1, md5 extraction
  - npm: Added sha1, md5 from dist metadata
  - pnpm_lock: Added sha256, md5 fields to ResolvedPackage
  - poetry_lock: Extract sha256 from files array
  - yarn_lock: Updated struct for new hash fields
- **Impact**: Comprehensive integrity verification data

#### Wave 3: Advanced Features (5 commits)

**1. Archive Safety Checks** (1 commit)

- **Problem**: Python wheel/egg extraction vulnerable to zip bombs and DoS
- **Solution**: Added 4-level safety checks
  - Archive size limit: 100MB
  - Per-file size limit: 50MB
  - Compression ratio validation: 100:1 max
  - Total extracted size tracking
- **Impact**: Protection against malicious archives

**2. License Declaration Extraction** (4 commits)

- **Problem**: License information from manifests not extracted or normalized
- **Solution**: Integrated askalono for license normalization across 4 parsers
  - npm: Extract from package.json "license" field
  - cargo: Extract from Cargo.toml "license" field
  - python: Extract from pyproject.toml, setup.py classifiers, PKG-INFO
  - maven: Extract from pom.xml `<licenses>` section
- **Features**:
  - Raw license string preserved in `extracted_license_statement`
  - Normalized to SPDX with askalono (confidence ‚â• 0.8)
  - Stored in `declared_license_expression` and `declared_license_expression_spdx`
  - Graceful fallback to raw strings when confidence is low
- **Impact**: Standardized, machine-readable license data across all parsers

#### Summary of Improvements

- **Safety**: Eliminated all panic-prone `.unwrap()` and `.expect()` calls
- **Data Quality**: Implemented `is_direct`, `is_pinned`, and comprehensive hash extraction
- **Security**: Added archive safety checks (size limits, compression ratio validation)
- **Features**: Initial license extraction with askalono integration (later refactored to separate detection)

---

## Table of Contents

1. [Guiding Principles](#guiding-principles)
2. [Current State](#current-state)
3. [Architectural Decisions](#architectural-decisions)
4. [Implementation Phases](#implementation-phases)
5. [Ecosystem Reference](#ecosystem-reference)
6. [Development Guidelines](#development-guidelines)
7. [Testing Strategy](#testing-strategy)
8. [Quality Gates](#quality-gates)
9. [Known Issues to Avoid](#known-issues-to-avoid)

---

## Guiding Principles

### 1. **Critical Analysis, Not Blind Translation**

- ‚ö†Ô∏è **DO NOT** blindly rewrite Python code in Rust
- ‚úÖ **DO** analyze the Python implementation to understand:
  - What problem is being solved?
  - Why was this approach chosen?
  - Are there better ways to solve this in Rust?
  - What bugs or limitations exist in the original?

### 2. **Reference, Don't Replicate**

Use `reference/scancode-toolkit/` as:

- ‚úÖ **Source of truth** for expected behavior and output formats
- ‚úÖ **Documentation** for understanding format specifications
- ‚úÖ **Test oracle** for verifying correctness
- ‚ùå **NOT** a template for implementation approach

### 3. **Rust-First Design**

Leverage Rust's strengths:

- **Type Safety**: Use strong types instead of runtime validation
- **Error Handling**: `Result<T, E>` instead of exception-based control flow
- **Ownership**: Avoid cloning where possible, use references
- **Iterators**: Lazy evaluation instead of eager list building
- **Pattern Matching**: Exhaustive matching instead of defensive checks

### 4. **Security & Robustness**

- **No Code Execution**: Never execute user-provided code (e.g., setup.py)
- **DoS Protection**: Implement limits on recursion, file size, memory
- **Input Validation**: Validate all external input with clear error messages
- **Fail Gracefully**: Parse errors should not crash the scanner

### 5. **Performance Optimization**

- **Lazy Parsing**: Only parse what's needed
- **Streaming**: Process large files without loading entirely into memory
- **Parallel Processing**: Use rayon for independent operations
- **Zero-Copy**: Use `&str` and `Cow` where appropriate

---

## Current State

### ‚úÖ Implemented Ecosystems (15 ecosystems, 42+ formats)

| Ecosystem      | Formats    | Status      | Notes                                                                                                                          |
| -------------- | ---------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **npm**        | 5          | ‚úÖ Complete | package.json, package-lock.json, yarn.lock (v1/v2), pnpm-lock.yaml, pnpm-workspace.yaml                                       |
| **Python**     | 11 formats | ‚úÖ Complete | pyproject.toml, setup.py (AST), setup.cfg, PKG-INFO, METADATA, poetry.lock, Pipfile/Pipfile.lock, requirements.txt, .whl, .egg |
| **Rust**       | 2          | ‚úÖ Complete | Cargo.toml, Cargo.lock                                                                                                         |
| **Maven**      | 4          | ‚úÖ Complete | pom.xml, pom.properties, MANIFEST.MF, .pom archives                                                                            |
| **Go**         | 3          | ‚úÖ Complete | go.mod, go.sum, Godeps.json                                                                                                    |
| **Dart**       | 2          | ‚úÖ Complete | pubspec.yaml, pubspec.lock                                                                                                     |
| **Composer**   | 2          | ‚úÖ Complete | composer.json, composer.lock                                                                                                   |
| **Ruby**       | 4          | ‚úÖ Complete | Gemfile, Gemfile.lock, .gemspec, .gem archives                                                                                 |
| **NuGet**      | 4          | ‚úÖ Complete | .nuspec, packages.config, packages.lock.json, .nupkg archives                                                                  |
| **Gradle**     | 2          | ‚úÖ Complete | build.gradle (Groovy), build.gradle.kts (Kotlin), gradle.lockfile                                                              |
| **Swift**      | 2          | ‚úÖ Complete | Package.resolved, Package.swift.json (with BLAKE3 caching)                                                                     |
| **CocoaPods**  | 4          | ‚úÖ Complete | Podfile, Podfile.lock, .podspec, .podspec.json                                                                                 |
| **Debian**     | 5          | ‚úÖ Complete | control, .deb archives, copyright, .dsc, installed database                                                                    |
| **RPM**        | 1          | ‚úÖ Complete | .rpm archives (with dependency extraction)                                                                                     |
| **Alpine**     | 2          | ‚úÖ Complete | installed database, .apk archives                                                                                              |

**Test Infrastructure**: Comprehensive unit and golden test coverage with documented blockers for detection-dependent features.

### Recent Quality Improvements

- ‚úÖ **Safety**: Zero `.unwrap()` or `.expect()` calls in parser code
- ‚úÖ **Data Accuracy**: Proper `is_direct` and `is_pinned` analysis
- ‚úÖ **Hash Extraction**: All 4 hash types (sha1, sha256, sha512, md5) extracted
- ‚úÖ **License Detection**: SPDX normalization via askalono integration
- ‚úÖ **Archive Security**: Size limits and compression ratio validation
- ‚úÖ **Error Handling**: Graceful fallback with warning logs

---

## Architectural Decisions

### Critical Separation of Concerns: Extraction vs Detection (Established Feb 2026)

**Decision**: Package parsers MUST extract ONLY. License detection, copyright holder detection, and author/email parsing from file content are separate pipeline stages.

**Rationale**:

- **Correctness**: Matches Python ScanCode Toolkit architecture (parsers extract, detection engines detect)
- **Separation of concerns**: Extraction (reading manifests) is fundamentally different from detection (analyzing text/patterns)
- **Maintainability**: Detection logic lives in ONE place, not scattered across parsers
- **Testability**: Can test extraction and detection independently
- **Scalability**: Detection engines can be enhanced without touching parsers

**Implementation Rules**:

#### License Detection

| Parser Responsibility                                   | Detection Engine Responsibility                                 |
| ------------------------------------------------------- | --------------------------------------------------------------- |
| ‚úÖ Populate `extracted_license_statement` with raw data | ‚úÖ Populate `declared_license_expression` with normalized SPDX  |
| ‚úÖ Extract license URLs, text, fields AS-IS             | ‚úÖ Populate `declared_license_expression_spdx` with proper case |
| ‚ùå NEVER call `normalize_license()`                     | ‚úÖ Populate `license_detections` array with Match objects       |
| ‚ùå NEVER call `resolve_license_url()`                   | ‚úÖ Map URLs to SPDX identifiers                                 |
| ‚ùå NEVER populate `declared_license_expression*`        | ‚úÖ Analyze license text with confidence scoring                 |
| ‚ùå NEVER populate `license_detections`                  | ‚úÖ Handle SPDX expression parsing                               |

#### Copyright & Holder Detection

| Parser Responsibility                    | Detection Engine Responsibility                       |
| ---------------------------------------- | ----------------------------------------------------- |
| ‚úÖ Extract raw copyright text (if in manifest) | ‚úÖ Populate `holder` field from copyright analysis    |
| ‚ùå NEVER parse/extract holder names      | ‚úÖ Use grammar-based copyright detection (ClueCODE)   |
| ‚ùå NEVER populate `holder` field         | ‚úÖ Scan file content for copyright statements         |
| ‚úÖ Set `holder: None`                    | ‚úÖ Extract holder names with pattern matching         |

#### Author/Email Parsing

| Parser Responsibility (Manifests)                | Detection Engine Responsibility (File Content)        |
| ------------------------------------------------ | ----------------------------------------------------- |
| ‚úÖ Parse author/email from manifests (e.g., npm) | ‚úÖ Scan source files for email patterns               |
| ‚úÖ Create `Party` objects with name/email/role   | ‚úÖ Parse Linux CREDITS files for authors              |
| ‚úÖ Use utilities like `parse_name_email()`       | ‚úÖ Separate plugin for email/author detection         |

**Data Flow**:

```
Parser (Extraction)                Detection Engine                 Final Output
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ manifest.json   ‚îÇ‚îÄ‚îÄextract‚îÄ‚îÄ>   ‚îÇ License Engine   ‚îÇ‚îÄ‚îÄdetect‚îÄ‚îÄ> ‚îÇ PackageData ‚îÇ
‚îÇ                 ‚îÇ               ‚îÇ                  ‚îÇ            ‚îÇ             ‚îÇ
‚îÇ "license": "MIT"‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> "MIT"            ‚îÇ            ‚îÇ declared:   ‚îÇ
‚îÇ                 ‚îÇ               ‚îÇ                  ‚îÇ            ‚îÇ   "mit"     ‚îÇ
‚îÇ                 ‚îÇ               ‚îÇ normalize()      ‚îÇ            ‚îÇ spdx: "MIT" ‚îÇ
‚îÇ                 ‚îÇ               ‚îÇ confidence: 1.0  ‚îÇ            ‚îÇ detections  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     PARSER STOPS HERE                    DETECTION HAPPENS HERE
     extracted_license_statement          declared_license_expression
     = "MIT"                              = "mit"
```

**When Detection Engine Will Be Built**:

- **Phase**: Post parser implementation (after 80%+ parser coverage)
- **Trigger**: When majority of parsers are complete
- **Location**: New module `src/detection/license_engine.rs`
- **Integration Point**: Scanner calls detection engine AFTER extraction

**Current Status** (Feb 2026):

- ‚úÖ **All parsers refactored**: License detection, copyright holder extraction removed from all parsers
- ‚úÖ **Architecture enforced**: Parsers extract ONLY, detection is separate
- ‚è≥ **Next phase**: Build separate detection engines (license, copyright, email)

**When Detection Engines Will Be Built**:

- **Phase**: Post parser implementation (after 80%+ parser coverage)
- **Trigger**: When majority of parsers are complete
- **Modules**:
  - `src/detection/license_engine.rs` - License detection and SPDX normalization
  - `src/detection/copyright_engine.rs` - Copyright and holder detection
  - `src/detection/email_engine.rs` - Email and author pattern detection
- **Integration Point**: Scanner calls detection engines AFTER extraction

**References**:

- Python reference:
  - `reference/scancode-toolkit/src/licensedcode/` (license detection)
  - `reference/scancode-toolkit/src/cluecode/copyrights.py` (copyright detection)
  - `reference/scancode-toolkit/src/cluecode/plugin_email.py` (email detection)
- Decision date: February 7, 2026

---

### Core Architecture (Established)

#### 1. **Trait-Based Parser System**

```rust
pub trait PackageParser {
    const PACKAGE_TYPE: &'static str;

    fn is_match(path: &Path) -> bool;
    fn extract_package_data(path: &Path) -> PackageData;
}
```

**Rationale**:

- Type-safe dispatch
- Compile-time guarantees
- Easy to test in isolation
- Clear contract for implementers

**Python Contrast**: Python uses runtime class inspection and dynamic dispatch.

#### 2. **Unified Data Model**

All parsers output `PackageData` struct:

- Normalizes differences between ecosystems
- SBOM-compliant output format
- Single source of truth for data structure

**Key Fields**:

- Package identity: name, version, namespace
- Metadata: description, homepage_url, parties
- Dependencies: with scope, requirements, resolved packages
- Licenses: detection with confidence scores, declared licenses with SPDX normalization
- Checksums: SHA256, SHA1, MD5, SHA512 for archives
- URLs: repository, download, API endpoints

#### 3. **Auto-Generated Documentation**

Using `inventory` crate + `register_parser!` macro:

- Runtime metadata collection
- Type-safe registration
- Automatic doc generation from code
- Pre-commit hook keeps docs in sync

**Rationale**: Documentation that can't go stale.

#### 4. **Golden Test Infrastructure**

- Reference outputs from ScanCode Toolkit
- Automated comparison
- Format-agnostic (JSON diffs)
- Regression prevention

#### 5. **Security-First Parsing**

- **AST-based parsing** for code files (setup.py, build.gradle)
- **No eval/exec**: Never execute user code
- **DoS limits**: Max file size, recursion depth, iteration count
- **Archive safety**: Size limits, compression ratio validation
- **Circular dependency detection**: Prevent infinite loops

#### 6. **Askalono Integration for License Normalization**

- **SPDX License Database**: ~600 licenses embedded at compile time
- **N-gram Analysis**: Fuzzy matching for license text
- **Confidence Threshold**: 0.8 (80%) for normalization
- **Graceful Fallback**: Use raw strings when confidence is low
- **Shared Utility**: `normalize_license()` function in `parsers/utils.rs`

**Rationale**: Standardized, machine-readable license data across all package formats.

---

## Implementation Phases

### Phase 0: Infrastructure (‚úÖ Complete)

- [x] Core data models (PackageData, Dependency, etc.)
- [x] Trait system (PackageParser)
- [x] Golden test framework
- [x] Auto-documentation system
- [x] Pre-commit hooks (fmt, clippy, doc generation)

### Phase 0.5: Parser Quality Enhancement (‚úÖ Complete - Feb 2025)

- [x] Safety: Remove all unwrap/expect calls (Wave 1)
- [x] Data Consistency: is_direct, is_pinned, namespace, hashes (Wave 2)
- [x] Advanced Features: Archive safety, license extraction (Wave 3)
- [x] Test Coverage: 305 ‚Üí 317 tests
- [x] Askalono Integration: License normalization across 4 parsers

### Phase 1: Top-Tier Modern Ecosystems (HIGH PRIORITY)

**Goal**: Cover 80% of real-world usage  
**Complexity**: Varies by parser (see breakdown below)
**Target**: +30 formats across 5 ecosystems

#### 1.1 Ruby / RubyGems ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.6

| Format        | Status      |
| ------------- | ----------- |
| Gemfile       | ‚úÖ Complete |
| Gemfile.lock  | ‚úÖ Complete |
| .gemspec      | ‚úÖ Complete |
| .gem archives | ‚úÖ Complete |

**Test Coverage**: 1/4 golden tests passing, 3 blocked on license detection

---

#### 1.2 Go ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.6

| Format             | Status      |
| ------------------ | ----------- |
| go.mod             | ‚úÖ Complete |
| go.sum             | ‚úÖ Complete |
| Godeps/Godeps.json | ‚úÖ Complete |

**Additional Formats Planned**: vendor/vendor.json, glide.yaml, glide.lock

**Test Coverage**: 4/4 golden tests passing

---

#### 1.3 PHP / Composer ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.6

| Format        | Status      |
| ------------- | ----------- |
| composer.json | ‚úÖ Complete |
| composer.lock | ‚úÖ Complete |

**Test Coverage**: 1/1 golden tests passing

---

#### 1.4 .NET / NuGet ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.6

| Format              | Status      |
| ------------------- | ----------- |
| packages.config     | ‚úÖ Complete |
| .nuspec             | ‚úÖ Complete |
| packages.lock.json  | ‚úÖ Complete |
| .nupkg archives     | ‚úÖ Complete |

**Additional Format Planned**: project.assets.json

**Test Coverage**: 0/6 golden tests passing (all blocked on license URL-to-SPDX mapping)

---

#### 1.5 Dart / Flutter / Pub ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.6

| Format       | Status      |
| ------------ | ----------- |
| pubspec.yaml | ‚úÖ Complete |
| pubspec.lock | ‚úÖ Complete |

**Test Coverage**: 4/4 golden tests passing

---

### Phase 2: Mobile & Build Systems (MEDIUM PRIORITY)

**Goal**: Cover mobile development ecosystems  
**Complexity**: Varies by parser (see breakdown below)
**Target**: +20 formats across 4 ecosystems

#### 2.1 Android / Gradle ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.7 (Wave 1-2-3)

| Format                    | Status      |
| ------------------------- | ----------- |
| build.gradle              | ‚úÖ Complete |
| build.gradle.kts (Kotlin) | ‚úÖ Complete |
| gradle.lockfile           | ‚úÖ Complete |

**Additional Formats Planned**: AndroidManifest.xml, .apk archives, .aar archives

**Implementation**: Custom token-based lexer + recursive descent parser (870 lines)

**Key Features**:

- All 5 dependency patterns supported
- Both Groovy and Kotlin DSL
- String interpolation preservation
- Project references, nested functions, map format

**Test Coverage**: 14 unit tests + 19 golden tests (15 passing, 4 documented as ignored)

---

#### 2.2 Swift / SwiftPM ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.7 (Wave 1-2-3)

| Format                    | Status      |
| ------------------------- | ----------- |
| Package.resolved          | ‚úÖ Complete |
| Package.swift.json (dump) | ‚úÖ Complete |

**Additional Format Planned**: Package.swift (native DSL parsing)

**Key Features**:

- v1/v2/v3 format support for Package.resolved
- BLAKE3 content-based caching for Package.swift.json (~100-500ms ‚Üí <1ms repeat parses)
- Graceful fallback when Swift toolchain unavailable

**Test Coverage**: 19 unit tests, 7 golden tests (all ignored - architectural difference documented)

---

#### 2.3 CocoaPods (iOS/macOS) ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.7 (Wave 1-2-3)

| Format        | Status      |
| ------------- | ----------- |
| Podfile       | ‚úÖ Complete |
| Podfile.lock  | ‚úÖ Complete |
| .podspec      | ‚úÖ Complete |
| .podspec.json | ‚úÖ Complete |

**Implementation**: Regex-based Ruby DSL parsers

**Key Features**:

- Full Podfile dependency parsing (pod syntax, git dependencies, local paths, subspecs)
- PodfileLockDataByPurl aggregation pattern for Podfile.lock
- Complete .podspec field extraction (name, version, license, author, source)
- Multiline description handling

**Test Coverage**: 24 tests (Podspec) + 17 tests (Podfile), 10 golden tests (all ignored - architectural difference documented)

---

#### 2.4 Bower (Legacy JavaScript)

**Priority**: ‚≠ê‚≠ê (Low - legacy)

| Format     | Complexity | Complexity |
| ---------- | ---------- | ---------- |
| bower.json | Low        | Low        |

**Key Challenges**:

- Simple JSON format
- Mostly deprecated in favor of npm

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/bower.py`

**Implementation Notes**:

- Straightforward JSON parsing with serde
- Similar structure to package.json
- Low priority due to ecosystem decline

---

### Phase 3: Scientific & Specialized (MEDIUM PRIORITY)

**Goal**: Cover scientific computing and specialized ecosystems  
**Complexity**: Varies by parser (see breakdown below)
**Target**: +15 formats across 4 ecosystems

#### 3.1 Conda (Python/R Scientific)

**Priority**: ‚≠ê‚≠ê‚≠ê‚≠ê (High)

| Format          | Complexity | Complexity |
| --------------- | ---------- | ---------- |
| meta.yaml       | Medium     | Medium     |
| environment.yml | Low        | Low        |
| conda.yaml      | Low        | Low        |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/conda.py`

**Implementation Notes**:

- All YAML formats (use serde_yaml)
- meta.yaml has Jinja2 templating (consider supporting or skip templated values)
- Focus on package and dependency information

**Known Python Issues to Avoid**:

- Python version attempts Jinja2 template evaluation (complex, error-prone)
- Missing validation of version selectors

---

#### 3.2 CRAN (R Language)

**Priority**: ‚≠ê‚≠ê‚≠ê (Medium)

| Format      | Complexity | Complexity |
| ----------- | ---------- | ---------- |
| DESCRIPTION | Low        | Low        |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/cran.py`

**Implementation Notes**:

- Debian control file format (key: value pairs)
- Similar to PKG-INFO parsing we already have
- Reuse RFC822 metadata parser pattern

---

#### 3.3 Conan (C++)

**Priority**: ‚≠ê‚≠ê‚≠ê (Medium)

| Format        | Complexity | Complexity |
| ------------- | ---------- | ---------- |
| conanfile.py  | Very High  | Very High  |
| conanfile.txt | Low        | Low        |
| conan.lock    | Medium     | Medium     |

**Key Challenges**:

- conanfile.py is Python code (requires AST parsing)
- Custom recipe format

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/conan.py`

**Implementation Notes**:

- **DO NOT** execute conanfile.py
- Use Python AST parsing (similar to setup.py approach)
- conanfile.txt is INI-like format
- conan.lock is JSON

**Known Python Issues to Avoid**:

- Python execution of conanfile.py (security risk)
- Incomplete AST extraction

---

#### 3.4 Haxe

**Priority**: ‚≠ê‚≠ê (Low - niche)

| Format       | Complexity | Complexity |
| ------------ | ---------- | ---------- |
| haxelib.json | Low        | Low        |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/haxe.py`

**Implementation Notes**:

- Simple JSON format
- Straightforward with serde_json

---

#### 3.5 OCaml / OPAM

**Priority**: ‚≠ê‚≠ê (Low - niche)

| Format     | Complexity | Complexity |
| ---------- | ---------- | ---------- |
| opam files | Medium     | Medium     |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/opam.py`

**Implementation Notes**:

- Custom format (key-value with S-expressions)
- Requires custom parser (nom)

---

### Phase 4: Linux Distribution Packages ‚úÖ COMPLETE (Feb 8, 2026)

**Goal**: Cover major Linux package managers  
**Status**: ‚úÖ All major formats implemented with beyond-parity features  
**Achieved**: 8 formats across 3 ecosystems

#### 4.1 Debian / Ubuntu (.deb) ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.8 (enhanced from earlier Phase 0.5)

| Format                  | Status      | Notes                                         |
| ----------------------- | ----------- | --------------------------------------------- |
| debian/control (source) | ‚úÖ Complete | RFC822 format with multiline field support    |
| control (binary)        | ‚úÖ Complete | Full metadata extraction                      |
| debian/copyright        | ‚úÖ Complete | DEP-5 machine-readable format                 |
| .deb archives           | ‚úÖ Complete | **BEYOND PARITY** - Full introspection (Python TODO) |
| dpkg status database    | ‚úÖ Complete | Installed package tracking                    |

**Key Challenges**:

- .deb archives are ar archives containing tar.gz archives
- debian/copyright uses machine-readable format (DEP-5)
- dpkg database is multi-record format

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/debian.py`
- `reference/scancode-toolkit/src/packagedcode/debian_copyright.py`

**Implementation Notes**:

- Control files use RFC822-like format
- .deb parsing requires ar + tar.gz extraction
- DEP-5 copyright format has specific schema

**Improvements Over Python**:

- ‚úÖ Complete copyright parsing with DEP-5 support
- ‚úÖ Proper multiline field handling
- ‚úÖ Archive introspection (Python has TODO)

**Test Coverage**: Multiple golden tests passing

---

#### 4.2 RPM / RedHat / Fedora ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.8

| Format                | Status           | Notes                                              |
| --------------------- | ---------------- | -------------------------------------------------- |
| .rpm archives         | ‚úÖ Complete      | **BEYOND PARITY** - Dependency extraction (Python TODO) |
| .spec files           | ‚è∏Ô∏è Not Planned   | Complex macro expansion, low priority              |
| RPM database (BDB)    | ‚è∏Ô∏è Not Planned   | Legacy format, low priority                        |
| RPM database (SQLite) | ‚è∏Ô∏è Not Planned   | Modern format, may add later                       |

**Key Challenges**:

- RPM format is complex binary format (cpio + header)
- .spec files are custom DSL with macros
- Multiple database formats (BDB, NDB, SQLite)

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/rpm.py`
- `reference/scancode-toolkit/src/packagedcode/spec.py`
- `reference/scancode-toolkit/src/packagedcode/pyrpm.py`

**Implementation Notes**:

- Consider using `rpm` crate if available, or parse manually
- .spec parser requires macro expansion (complex)
- RPM header parsing is well-documented but intricate

**Improvements Over Python**:

- ‚úÖ Dependency extraction with version constraints (Python has multiple TODOs)
- ‚úÖ Uses `rpm` crate for safe binary parsing
- ‚úÖ Formats requirements properly: `"libc.so.6 >= 2.2.5"`
- ‚úÖ Added bzip2 compression support

**Test Coverage**: 11 tests passing

**Implementation**: Leverages `rpm` crate v0.18 with all compression features (gzip, xz, zstd, bzip2)

---

#### 4.3 Alpine (.apk) ‚úÖ COMPLETE

**Status**: ‚úÖ Implemented in Phase 0.8

| Format             | Status           | Notes                                                      |
| ------------------ | ---------------- | ---------------------------------------------------------- |
| APKBUILD           | ‚è∏Ô∏è Not Planned   | Shell script execution risk, low priority                  |
| .apk archives      | ‚úÖ Complete      | Full PKGINFO extraction from tar.gz                        |
| installed database | ‚úÖ Complete      | **BEYOND PARITY** - SHA1 decoding + provider extraction   |

**Key Challenges**:

- APKBUILD is shell script (requires bash parsing)
- .apk archives are tar.gz with specific structure

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/alpine.py`

**Implementation Notes**:

- **DO NOT** execute APKBUILD shell scripts
- Use AST parsing for shell scripts (tree-sitter-bash)
- .apk format is simpler than .rpm

**Improvements Over Python**:

- ‚úÖ SHA1 checksum decoding (Python bug - always returns `null`)
- ‚úÖ Provider field extraction (Python explicitly doesn't implement)
- ‚úÖ Case-sensitive field parsing (P: vs p:)
- ‚úÖ File references with attributes and checksums

**Test Coverage**: 13 tests passing (12 active, 1 beyond-parity documented)

**Implementation**:

- Extracts F/R/Z/a fields from raw text (directory, filename, checksum, attributes)
- Decodes Q1-prefixed base64 SHA1 to hex
- Extracts provider entries (commands, shared libraries) into `extra_data.providers`

---

#### 4.4 FreeBSD

**Priority**: ‚≠ê‚≠ê (Low - specialized)

| Format            | Complexity | Complexity |
| ----------------- | ---------- | ---------- |
| Package manifests | Medium     | Medium     |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/freebsd.py`

---

### Phase 5: Legacy & Specialized (LOW PRIORITY)

**Goal**: Comprehensive coverage of niche ecosystems  
**Complexity**: Varies by parser (see breakdown below)
**Target**: +40 formats across 20+ ecosystems

#### 5.1 Chef (DevOps)

| Format         | Complexity | Complexity |
| -------------- | ---------- | ---------- |
| metadata.rb    | High       | Medium     |
| metadata.json  | Low        | Low        |
| Berksfile      | High       | Medium     |
| Berksfile.lock | Low        | Low        |

**Reference Files**:

- `reference/scancode-toolkit/src/packagedcode/chef.py`

---

#### 5.2 CPAN (Perl)

| Format      | Complexity | Complexity |
| ----------- | ---------- | ---------- |
| META.json   | Low        | Low        |
| META.yml    | Low        | Low        |
| Makefile.PL | Very High  | Very High  |
| dist.ini    | Medium     | Medium     |
| MANIFEST    | Low        | Low        |

**Reference Files**: TBD (not in current reference)

---

#### 5.3 Build Systems & Misc

| Ecosystem  | Formats                 | Priority | Effort |
| ---------- | ----------------------- | -------- | ------ |
| Bazel      | BUILD files             | ‚≠ê‚≠ê     | High   |
| Buck       | BUCK files, metadata    | ‚≠ê       | High   |
| Autotools  | configure.ac, configure | ‚≠ê       | Medium |
| Ivy (Java) | ivy.xml                 | ‚≠ê‚≠ê     | Medium |
| Meteor     | package.js              | ‚≠ê       | Medium |

---

#### 5.4 Binary Formats & Archives

| Format                 | Complexity | Complexity |
| ---------------------- | ---------- | ---------- |
| MSI (Windows)          | Very High  | Very High  |
| Windows PE (.exe/.dll) | Very High  | Very High  |
| JAR (Java)             | Medium     | Medium     |
| WAR (Java)             | Medium     | Medium     |
| EAR (Java)             | Medium     | Medium     |
| ISO images             | High       | High       |
| DMG (macOS)            | High       | High       |

**Note**: These require binary format parsing and are lower priority due to specialized use cases.

---

#### 5.5 AboutCode & Metadata

| Format         | Complexity | Complexity |
| -------------- | ---------- | ---------- |
| .ABOUT files   | Low        | Low        |
| README parsers | Medium     | Medium     |

---

## Development Guidelines

### For Each New Parser Implementation

#### Step 1: Research & Analysis

1. **Understand the Ecosystem**
   - Read official documentation
   - Study format specifications
   - Identify common use cases

2. **Analyze Python Reference**

   ```bash
   cd reference/scancode-toolkit
   grep -r "class.*Handler" src/packagedcode/<ecosystem>.py
   ```

   - What does the Python code do?
   - Why does it make these choices?
   - What are the edge cases?
   - What tests exist?

3. **Identify Issues**
   - Security vulnerabilities (code execution)
   - Performance bottlenecks (O(n¬≤) algorithms, excessive cloning)
   - Bugs (incorrect parsing, missing fields)
   - Missing features (incomplete format support)

4. **Design Improvements**
   - How can we do this better in Rust?
   - What types make this safer?
   - Where can we use iterators instead of vectors?
   - Can we parse streaming instead of loading entire file?

#### Step 2: Create Test Data

1. **Collect Real-World Examples**
   - Find popular open-source projects using this format
   - Include edge cases (empty files, unusual syntax, large files)
   - Add malformed examples for error handling

2. **Generate Golden Outputs**

   ```bash
   scancode -p <testfile> --json <output.json>
   ```

3. **Document Test Coverage**
   - What scenarios are tested?
   - What edge cases are covered?
   - What's intentionally not supported?

#### Step 3: Implement Parser

1. **Create Parser File**

   ```
   src/parsers/<ecosystem>.rs
   ```

2. **Implement PackageParser Trait**

   ```rust
   pub struct MyParser;

   impl PackageParser for MyParser {
       const PACKAGE_TYPE: &'static str = "ecosystem-name";

       fn is_match(path: &Path) -> bool {
           // File pattern matching
       }

       fn extract_package_data(path: &Path) -> PackageData {
           // Parsing logic
       }
   }
   ```

3. **Register Metadata**

   ```rust
   crate::register_parser!(
       "Description",
       &["**/pattern.json"],
       "package-type",
       "Language",
       Some("https://docs.url"),
   );
   ```

4. **Add Module Declaration**

   ```rust
   // In src/parsers/mod.rs
   pub mod my_parser;
   ```

#### Step 4: Write Tests

1. **Unit Tests**

   ```rust
   #[cfg(test)]
   mod tests {
       use super::*;

       #[test]
       fn test_is_match() { /* ... */ }

       #[test]
       fn test_extract_basic() { /* ... */ }

       #[test]
       fn test_extract_complex() { /* ... */ }

       #[test]
       fn test_malformed_input() { /* ... */ }
   }
   ```

2. **Golden Tests**

   ```
   testdata/<ecosystem>/
     ‚îú‚îÄ‚îÄ simple/
     ‚îÇ   ‚îú‚îÄ‚îÄ manifest.json
     ‚îÇ   ‚îî‚îÄ‚îÄ expected.json
     ‚îî‚îÄ‚îÄ complex/
         ‚îú‚îÄ‚îÄ manifest.json
         ‚îî‚îÄ‚îÄ expected.json
   ```

3. **Test Coverage Goals**
   - ‚úÖ Basic functionality
   - ‚úÖ Edge cases (empty, minimal, maximal)
   - ‚úÖ Error handling (malformed, missing fields)
   - ‚úÖ Performance (large files)
   - ‚úÖ Security (malicious input)

#### Step 5: Documentation

1. **Module-Level Documentation**

   ```rust
   //! Parser for <ecosystem> package manifests.
   //!
   //! Supports the following formats:
   //! - Format 1: description
   //! - Format 2: description
   //!
   //! # Key Features
   //! - Feature 1
   //! - Feature 2
   //!
   //! # Implementation Notes
   //! - Note 1
   //! - Note 2
   ```

2. **Public API Documentation**

   ````rust
   /// Parser for <ecosystem> package manifests.
   ///
   /// # Examples
   ///
   /// ```no_run
   /// use scancode_rust::parsers::my_parser::MyParser;
   /// // ...
   /// ```
   ````

3. **Update SUPPORTED_FORMATS.md**

   ```bash
   cargo run --bin generate-supported-formats
   ```

#### Step 6: Review & Quality Gates

1. **Self-Review Checklist**
   - [ ] All tests pass (`cargo test`)
   - [ ] No clippy warnings (`cargo clippy`)
   - [ ] Code formatted (`cargo fmt`)
   - [ ] Documentation complete (`cargo doc`)
   - [ ] No unsafe code (unless absolutely necessary and documented)
   - [ ] No unwrap/expect in library code
   - [ ] Error messages are clear and actionable
   - [ ] Performance tested with large files

2. **Security Checklist**
   - [ ] No code execution (eval, exec, subprocess)
   - [ ] Input validation (file size, recursion depth)
   - [ ] DoS protection (limits on iterations, memory)
   - [ ] Safe parsing (no panic on malformed input)

3. **Comparison with Python**
   - [ ] Feature parity achieved
   - [ ] Known bugs NOT replicated
   - [ ] Performance improvements documented
   - [ ] Edge cases handled better

---

## Testing Strategy

### Test Pyramid

```
       /\
      /  \    Integration Tests (Golden Tests)
     /    \   - Compare output with ScanCode Toolkit
    /------\  - End-to-end format validation
   /        \
  /   Unit   \ Unit Tests
 /   Tests    \ - Parser functions
/______________\ - Helper utilities
```

### Golden Test Workflow

1. **Generate Reference Output**

   ```bash
   cd reference/scancode-toolkit
   scancode -p testdata/npm/package.json --json expected.json
   ```

2. **Run Rust Parser**

   ```rust
   #[test]
   fn test_golden_npm_simple() {
       let result = NpmParser::extract_package_data(Path::new("testdata/npm/package.json"));
       let expected = read_expected_json("testdata/npm/expected.json");
       assert_eq_ignore_order(result, expected);
   }
   ```

3. **Continuous Validation**
   - Pre-commit hook runs golden tests
   - CI runs full test suite
   - Regression detection automatic

### Performance Testing

For each parser:

- Benchmark with `criterion` crate
- Test with 1KB, 100KB, 10MB files
- Memory profiling with `valgrind`/`heaptrack`
- Ensure O(n) or better complexity

---

## Quality Gates

### Before Merging Parser Implementation

1. **Functionality**
   - [ ] All documented formats supported
   - [ ] Feature parity with ScanCode Toolkit
   - [ ] Edge cases handled gracefully

2. **Code Quality**
   - [ ] Zero clippy warnings
   - [ ] Code formatted with rustfmt
   - [ ] Documentation complete
   - [ ] No TODO/FIXME without GitHub issue

3. **Testing**
   - [ ] Unit test coverage >90%
   - [ ] Golden tests pass
   - [ ] Performance benchmarks acceptable
   - [ ] Security tests pass

4. **Security**
   - [ ] No code execution
   - [ ] Input validation present
   - [ ] DoS protection implemented
   - [ ] Security review documented

5. **Documentation**
   - [ ] Public API documented
   - [ ] Module-level documentation present
   - [ ] SUPPORTED_FORMATS.md updated
   - [ ] Known limitations documented
   - [ ] Migration notes (if applicable)

---

## Future Detection Engines

These will be implemented after reaching 80%+ parser coverage:

### License Detection Engine

- SPDX normalization with fuzzy matching
- License text analysis from files
- URL-to-SPDX mapping
- Multi-license expression building

### Copyright & Holder Detection Engine

- Grammar-based copyright statement detection
- Holder name extraction with pattern matching
- File content scanning for copyright notices

### Email & Author Detection Engine

- Email pattern detection from source files
- Linux CREDITS file parsing
- Author attribution analysis

---

## Known Issues to Avoid (from Python Reference)

### Security Issues

1. **Code Execution**
   - ‚ùå Python's `eval()` / `exec()` in setup.py parsing
   - ‚ùå Ruby execution in Gemfile/Podfile parsing
   - ‚ùå Shell execution in APKBUILD parsing
   - ‚ùå Groovy execution in Gradle parsing
   - ‚úÖ Solution: AST parsing only, never execute

2. **DoS Vulnerabilities**
   - ‚ùå No recursion depth limits
   - ‚ùå No file size limits
   - ‚ùå Quadratic complexity in nested loops
   - ‚úÖ Solution: Explicit limits, O(n) algorithms

3. **Path Traversal**
   - ‚ùå Inadequate path sanitization in archive extraction
   - ‚úÖ Solution: Strict path validation, use `Path::canonicalize()`

### Correctness Issues

1. **Incomplete Parsing**
   - ‚ùå Missing fields in .nuspec files
   - ‚ùå Partial support for PEP 508 markers
   - ‚ùå Incomplete go.mod directive support
   - ‚úÖ Solution: Comprehensive format coverage, exhaustive testing

2. **Version Handling**
   - ‚ùå No validation of semantic versions
   - ‚ùå Incorrect range parsing (e.g., `^1.2.3`)
   - ‚úÖ Solution: Use `semver` crate, validate all versions

3. **Encoding Issues**
   - ‚ùå Assumes UTF-8 everywhere
   - ‚ùå Poor handling of BOM markers
   - ‚úÖ Solution: Explicit encoding detection/handling

### Performance Issues

1. **Memory Usage**
   - ‚ùå Loading entire large files into memory
   - ‚ùå Excessive cloning of strings
   - ‚úÖ Solution: Streaming parsers, use `&str` and `Cow`

2. **Algorithmic Complexity**
   - ‚ùå O(n¬≤) nested loops in dependency resolution
   - ‚ùå Repeated regex compilation
   - ‚úÖ Solution: Use iterators, compile regex once with `lazy_static`

3. **Unnecessary Work**
   - ‚ùå Parsing entire file when only subset needed
   - ‚ùå Computing unused fields
   - ‚úÖ Solution: Lazy evaluation, parse on demand

### Design Issues

1. **Error Handling**
   - ‚ùå Silent failures (returns empty result)
   - ‚ùå Generic error messages ("failed to parse")
   - ‚ùå Exceptions used for control flow
   - ‚úÖ Solution: Detailed `Result<T, E>` errors with context

2. **Type Safety**
   - ‚ùå Runtime type checking with `isinstance()`
   - ‚ùå Optional fields as `None` vs absent
   - ‚úÖ Solution: Strong typing with enums, `Option<T>`

3. **Modularity**
   - ‚ùå Large monolithic functions (500+ lines)
   - ‚ùå Tight coupling between parsers
   - ‚úÖ Solution: Small focused functions, trait-based design

---

## Documentation Strategy (‚úÖ COMPLETE)

### Overview

All documentation phases have been completed, establishing a permanent, scalable documentation system. For complete details, see [DOCUMENTATION_SUMMARY.md](DOCUMENTATION_SUMMARY.md).

### What Was Created

#### 1. Architectural Decision Records (ADRs) - `docs/adr/`

**Purpose**: Permanent record of key architectural decisions with context and rationale.

| ADR | Title | Key Points |
|-----|-------|-----------|
| [0001](adr/0001-trait-based-parsers.md) | Trait-Based Parser Architecture | Type-safe dispatch, compile-time guarantees, zero-cost abstractions |
| [0002](adr/0002-extraction-vs-detection.md) | Extraction vs Detection Separation | Parsers extract only, detection is separate pipeline stage |
| [0003](adr/0003-golden-test-strategy.md) | Golden Test Strategy | Validation against Python reference, documented exceptions |
| [0004](adr/0004-security-first-parsing.md) | Security-First Parsing | No code execution, DoS protection, archive safety |
| [0005](adr/0005-auto-generated-docs.md) | Auto-Generated Documentation | Hybrid approach: auto-gen + manual + inline docs |

#### 2. Beyond-Parity Improvements - `docs/improvements/`

**Purpose**: Document features where scancode-rust exceeds Python ScanCode.

| Parser | Improvement Type | Impact |
|--------|-----------------|---------|
| [Alpine](improvements/alpine-parser.md) | üêõ Bug Fix + ‚ú® Feature | SHA1 decoding + provider extraction |
| [RPM](improvements/rpm-parser.md) | ‚ú® New Feature | Full dependency extraction |
| [Debian](improvements/debian-parser.md) | ‚ú® New Feature | .deb archive introspection |
| [Composer](improvements/composer-parser.md) | üîç Enhanced | 7 extra provenance fields |
| [Ruby](improvements/ruby-parser.md) | üîç Enhanced | Semantic party model |
| [Dart](improvements/dart-parser.md) | üîç Enhanced | Scope + YAML preservation |
| [Gradle](improvements/gradle-parser.md) | üõ°Ô∏è Security | No code execution |

#### 3. System Architecture - `docs/ARCHITECTURE.md`

**Purpose**: Comprehensive system design documentation.

**Contents**:

- Core principles (correctness, security, extraction vs detection)
- Component architecture (trait system, data model, pipeline)
- Security layers (4-layer defense)
- Testing strategy (golden tests, coverage)
- Performance characteristics
- Future work roadmap

#### 4. Inline API Documentation

**Purpose**: Developer-facing API reference via `cargo doc`.

**Coverage**:

- Crate-level documentation in lib.rs
- Module-level `//!` comments for all parsers
- Function-level `///` doc comments for public API

#### 5. User Documentation - Enhanced `README.md`

**Enhanced with**:

- Status badges
- Ecosystem overview with format counts
- Key features section
- Comprehensive documentation links

#### 6. Auto-Generated Format List

**File**: `docs/SUPPORTED_FORMATS.md` (auto-generated)

**Process**:

1. Parser metadata collected via `inventory` crate
2. `src/bin/generate-supported-formats.rs` generates markdown table
3. Pre-commit hook automatically regenerates on parser changes
4. Configuration: `.pre-commit-config.yaml` (already existed)

**Ensures**: Documentation can never go out of sync with code

### Documentation Principles Applied

1. **Can't Go Stale**: Auto-generated from code where possible
2. **Multiple Audiences**: End users (README), API users (cargo doc), contributors (ADRs, ARCHITECTURE)
3. **Searchable & Linkable**: Cross-references between documents
4. **Evidence-Based**: Code examples, test verification, Python comparisons
5. **Maintainable**: Templates and patterns for adding new parser docs

### Future Maintenance

**When Adding New Parser**:

1. Parser code automatically includes metadata (via `register_parser!` or trait impl)
2. Pre-commit hook regenerates `SUPPORTED_FORMATS.md`
3. Add module `//!` docs following template (5-10 minutes)
4. If improvement over Python: Create `docs/improvements/{parser}.md` (30-60 minutes)
5. Update count in README.md if new ecosystem (1 minute)

**Estimated Effort Per Parser**: 5-60 minutes depending on whether it's an improvement

### Documentation Structure

See [DOCUMENTATION_SUMMARY.md](DOCUMENTATION_SUMMARY.md) for complete documentation structure and metrics.

### Success Metrics

‚úÖ **Complete API Documentation**: `cargo doc` produces comprehensive docs  
‚úÖ **Searchable Knowledge Base**: All decisions documented with rationale  
‚úÖ **User-Friendly**: Clear entry points (README ‚Üí ARCHITECTURE ‚Üí ADRs ‚Üí API docs)  
‚úÖ **Maintainable**: Auto-generation prevents staleness  
‚úÖ **Professional**: Matches or exceeds documentation quality of major Rust projects  

### References

- **ADR Format**: Based on [Michael Nygard's ADR pattern](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)
- **Rust Doc Style**: Following [Rust API Guidelines](https://rust-lang.github.io/api-guidelines/documentation.html)
- **Python Reference**: Analyzed ScanCode Toolkit's Sphinx + RST documentation approach
- **Auto-generation**: Inspired by Python's `regen_package_docs.py` but adapted for Rust

---

## Conclusion

This plan provides a comprehensive roadmap to full parser parity with ScanCode Toolkit. By following these guidelines and prioritizing high-impact ecosystems first, scancode-rust can achieve:

1. **Better Security**: No code execution, robust input validation, archive safety
2. **Better Performance**: Streaming parsers, optimized algorithms
3. **Better Maintainability**: Type safety, clear error handling, comprehensive documentation
4. **Better Testability**: Comprehensive test coverage, golden tests
5. **Better Data Quality**: Proper dependency tracking, accurate detection separation

The strong architectural foundation established in Phase 0 (extraction vs detection separation, trait-based parsers, security-first design) positions the project for sustainable growth toward full ScanCode Toolkit parity.
